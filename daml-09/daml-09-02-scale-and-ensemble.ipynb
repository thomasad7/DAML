{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAML 09 - Scaling and Ensembles\n",
    "\n",
    "Michal Grochmal <michal.grochmal@city.ac.uk>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data does not always come in a way our machine learning algorithms expects it.\n",
    "We saw that concept a handful of times already:\n",
    "we extracted extra features (e.g. polynomial features),\n",
    "we did dimensionality reduction,\n",
    "we used manifold techniques.\n",
    "Yet, all these things may still fail against certain data.\n",
    "\n",
    "Note: This section is very dependent on the values produced by the random number generator.\n",
    "You may want to run each piece of code several times.\n",
    "\n",
    "For a start we import the usual stuff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn-talk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then the wine dataset,\n",
    "which is an example of data that would fail a simple dimensionality reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "wine = load_wine()\n",
    "print(wine['DESCR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One should explore the data first.\n",
    "We will simply plot as many dimensions as we can at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.scatter(wine.data[:, 0], wine.data[:, 1], s=30*wine.data[:, 2], c=wine.target, cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes seem to be difficult to separate.\n",
    "Yet, we have just a few dimensions and a handful of samples,\n",
    "therefore we can perform a full PCA and see whether we can project this data into a different space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "pca.fit(wine.data)\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "ax.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "ax.set(xlabel='components', ylabel='explained variance');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oh wow, two dimensional space seem to explain the data variance well enough.\n",
    "And, since we can visualize a two dimensional space easily, we should do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "wine_pca = pca.fit_transform(wine.data)\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.scatter(wine_pca[:, 0], wine_pca[:, 1], s=60, c=wine.target, cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite the fact that we did dimensionality reduction the data does not look separable.\n",
    "Let's try something different, let's describe this data using `pandas`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(wine.data, columns=[wine.feature_names])\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values of *magnesium* and *proline* have completely different magnitudes from all other features.\n",
    "These features have much bigger values than all the others,\n",
    "and since PCA will evaluate variance based on the values alone,\n",
    "it will take these two features as the main variance explanation.\n",
    "In other words, instead of finding the main variance in the data PCA is simply finding these two features.\n",
    "Let's scale those things down and then apply PCA.\n",
    "\n",
    "The `StandardScaler` centers the mean of every feature to zero,\n",
    "and ensures that the variance of each feature is exactly one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "preprocess = make_pipeline(StandardScaler(), PCA(n_components=2))\n",
    "wine_pca = preprocess.fit_transform(wine.data)\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.scatter(wine_pca[:, 0], wine_pca[:, 1], s=60, c=wine.target, cmap='viridis');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now this is rather easy to separate.\n",
    "And moreover, we probably do not need a complex classifier for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "A decision tree is a rather simple classifier (or regressor).\n",
    "During training a decision tree learns rules that divide\n",
    "the feature space perpendicular to a feature.\n",
    "In other words, at each training step,\n",
    "the tree divides one dimension into two groups.\n",
    "\n",
    "At the first training step the tree divides the entire feature space.\n",
    "On all following steps the tree attempt to divide each resulting divided branch further.\n",
    "This happens until all leaves contain only data with the same label,\n",
    "or a stopping criteria is reached.\n",
    "\n",
    "There are several algorithms to train a decision tree.\n",
    "The algorithms are concerned in how, at each step, perform the best split.\n",
    "At each step a tree can split the feature space into two separate areas using any of the features.\n",
    "Therefore each feature is evaluated for the best split so that as many labels are separated,\n",
    "then an information gain measure is used to decide which split produces the tree that better\n",
    "slits classes apart.\n",
    "The information gain measure differs between algorithms, most often we:\n",
    "\n",
    "Take the split which minimizes the *gini* impurity:\n",
    "\n",
    "$$\n",
    "\\sum_k \\left[ \\frac{\\sum_i I(y_i = k)}{N} \\left( 1 - \\frac{\\sum_i I(y_i = k)}{N} \\right) \\right]\n",
    "$$\n",
    "\n",
    "or, take the split which minimizes *cross-entropy*\n",
    "\n",
    "$$\n",
    "\\sum_k \\left[ - \\frac{\\sum_i I(y_i = k)}{N} log \\left( \\frac{\\sum_i I(y_i = k)}{N} \\right) \\right]\n",
    "$$\n",
    "\n",
    "or even the split which minimizes the maximum misclassification error\n",
    "\n",
    "$$\n",
    "\\sum_k \\left[ 1 - max \\left( \\frac{\\sum_i I(y_i = k)}{N} \\right) \\right]\n",
    "$$\n",
    "\n",
    "Where $k$ is each class and $N$ the number of samples being split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No matter the split method the algorithm is always a greedy algorithm.\n",
    "The tree will always attempt the split that will reduce the impurity the most *at the current step*.\n",
    "By no means this guarantees that the final tree will be optimal,\n",
    "or have the minimum overall impurity.\n",
    "\n",
    "The stopping criteria are ways of making the tree not overfit the data.\n",
    "We can define when leaves are too small to split or an overall maximum number of splits.\n",
    "Without any criteria we will just split the data as much as we can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(wine_pca, wine.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As most `sklearn` classes the decision tree classifier has some sensible defaults.\n",
    "We can look at how to classified the (dimensionality) reduces wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16, 7))\n",
    "ax.scatter(wine_pca[:, 0], wine_pca[:, 1], s=60, c=wine.target, cmap='viridis', zorder=2)\n",
    "xlim = ax.get_xlim()\n",
    "ylim = ax.get_ylim()\n",
    "x = np.linspace(*xlim, num=200)\n",
    "y = np.linspace(*ylim, num=200)\n",
    "xx, yy = np.meshgrid(x, y)\n",
    "z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "ax.contourf(xx, yy, z, alpha=0.2, cmap='viridis', zorder=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good enough for such a simple classifier.\n",
    "We can see overfitting but we can deal with that later.\n",
    "\n",
    "Decision trees are simple and computationally cheap to use for multilabel classification,\n",
    "also this is a model that can estimate class probabilities.\n",
    "We can also extract the rules the tree has learned to explain what it is doing.\n",
    "In other words, the decision tree is a white-box model.\n",
    "\n",
    "That said, plain decision trees are very sensitive to outliers and variations in data.\n",
    "One needs to ensure that data fed to a decision tree is scaled and has similar\n",
    "support across all classes.\n",
    "Trees tend to be biased to the most often found classes.\n",
    "\n",
    "We should try to evaluate the generalization of our tree classifier.\n",
    "We take a test set and compare that with a cross-validation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(wine_pca, wine.target, test_size=0.2)\n",
    "model = DecisionTreeClassifier()\n",
    "model.fit(xtrain, ytrain)\n",
    "print('cross validation', cross_val_score(model, xtrain, ytrain))\n",
    "print('test score', model.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, a decision tree has the bad habit of overfitting the data.\n",
    "Moreover, with dimensionality reduced data we cannot take advantage of the white-box model.\n",
    "This is because we cannot tell the meaning of the features after the reduction,\n",
    "the new features are just a plane that contains the most variation.\n",
    "\n",
    "Yet, training several trees and then bagging them together makes up for it.\n",
    "Such ensembles are some of the most powerful classifiers,\n",
    "these can draw very fluid decision boundaries between several classes at once.\n",
    "When using several trees at once,\n",
    "we lose the capacity of explaining what the model is doing (white-box),\n",
    "yet for already (dimensionality) reduced data it does not matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(wine_pca, wine.target, test_size=0.2)\n",
    "models = ['Bagging', 'Random Forest', 'Ada Boost']\n",
    "model_dict = {\n",
    "    'Bagging': BaggingClassifier(DecisionTreeClassifier(), n_estimators=30, max_samples=0.7),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=30),\n",
    "    'Ada Boost': AdaBoostClassifier(n_estimators=30)\n",
    "}\n",
    "fig, ax = plt.subplots(len(models), figsize=(16, 24))\n",
    "for i, model_name in enumerate(models):\n",
    "    model = model_dict[model_name]\n",
    "    model.fit(xtrain, ytrain)\n",
    "    ax[i].scatter(wine_pca[:, 0], wine_pca[:, 1], s=60, c=wine.target, cmap='viridis', zorder=2)\n",
    "    xlim = ax[i].get_xlim()\n",
    "    ylim = ax[i].get_ylim()\n",
    "    x = np.linspace(*xlim, num=200)\n",
    "    y = np.linspace(*ylim, num=200)\n",
    "    xx, yy = np.meshgrid(x, y)\n",
    "    z = model.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "    ax[i].contourf(xx, yy, z, alpha=0.2, cmap='viridis', zorder=1)\n",
    "    ax[i].set_title(model_name, fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging\n",
    "\n",
    "Is the technique of simply training several trees on subsamples of the data.\n",
    "Then taking the majority vote when predicting.\n",
    "\n",
    "The sub-sampling is done *with replacement*,\n",
    "meaning that the same sample can be selected several times into a bag.\n",
    "In ensemble terms the sub-sampling with replacement is called **bootstrapped**.\n",
    "\n",
    "A variant of the bagging algorithm is called *pasting*.\n",
    "The difference with bagging is that in pasting the bags are taken not bootstrapped.\n",
    "In other words, pasting is an algorithm that performs data sub-sampling\n",
    "*without replacement* and then trains trees on these subsamples.\n",
    "Pasting only really works on very big datasets.\n",
    "\n",
    "### Random Forest\n",
    "\n",
    "Apart from varying the number of samples each tree will see\n",
    "we can also variate the features it will see.\n",
    "A *random forest* trains several trees each on a sub-sample of the data\n",
    "and a sub-sample of the features.\n",
    "The sub-sampling can be performed *bootstrapped* (the default in `sklearn`) or not.\n",
    "\n",
    "The higher randomization increases the variance of the model.\n",
    "But the fact that we train several models and then take the majority vote\n",
    "reduces the variance again.\n",
    "The big advantage of random forests and bagging is the fact that\n",
    "each ensemble model can be trained separately.\n",
    "Which also means that it is easy to parallelize the algorithm across processes or even machines.\n",
    "\n",
    "### Ada Boost\n",
    "\n",
    "Boosting algorithms take a slightly different approach.\n",
    "They train a very simple classifier with very high regularization,\n",
    "e.g. a tree that can only split the data once (also called a tree stump).\n",
    "Then the boosting algorithm finds the samples that the very simple classifier got wrong,\n",
    "and updates the data set to put more weights to these samples.\n",
    "\n",
    "Then the boosting algorithm trains a new very simple classifier (stump)\n",
    "on the new, updated, dataset.\n",
    "It is likely that the new classifier will classify the weighted samples correctly,\n",
    "at the expense of the other samples.\n",
    "On the next step the boosting algorithm again evaluates the just trained simple classifier,\n",
    "and find the samples that this new classifier got wrong.\n",
    "Now the algorithm puts more weight on the samples misclassified by the newest\n",
    "classifier and trains yet another simple classifier on that set.\n",
    "The algorithm repeats until the maximum number of simple classifiers (stumps) is reached.\n",
    "\n",
    "The final answer from the algorithm is either a majority vote, or a weighted vote\n",
    "(by misclassification error of each classifier or by predicted probabilities).\n",
    "\n",
    "Ada Boost is the original algorithm, with several variant following it.\n",
    "In general, boosting produces better results than bagging or pasting.\n",
    "Yet, the fact that the ensemble cannot be parallelized makes the algorithm\n",
    "less practical for use with very big datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "The most common technique often used is the random forest.\n",
    "This is thanks to the fact that it is easy to parallelize and produces\n",
    "better results than plain bagging (or pasting) as the number of estimators increase.\n",
    "\n",
    "Let's evaluate the performance of a random forest against the simple decision tree from before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(n_estimators=30)\n",
    "model.fit(xtrain, ytrain)\n",
    "print('cross validation', cross_val_score(model, xtrain, ytrain))\n",
    "print('test score', model.score(xtest, ytest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tuned ensemble will perform better than a simple classifier, in most cases.\n",
    "\n",
    "Decision trees are not the only estimators that can be used inside bagging or boosting algorithms.\n",
    "Any simple classifier can benefit from ensemble methods.\n",
    "Yet, the simplicity and possibility of tuning of trees make them the most common\n",
    "classifiers used in big ensembles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to an old dataset - Iris\n",
    "\n",
    "Let's check out the random forest in action on a slightly more complicated dataset.\n",
    "The wine dataset above has very little overlap between classes but, if you remember,\n",
    "the Iris dataset has a good separation of the *setosa* flower but a big\n",
    "overlap between *versicolor* and *virginica*.\n",
    "A random forest should be capable of drawing a decision boundary between the classes nevertheless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(iris.data, iris.target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we should evaluate this properly.\n",
    "We will tune the hyperparameters of the random forest through cross-validation,\n",
    "therefore we cannot use the result of that as a generalization score.\n",
    "We take out a test set to evaluate with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "model = RandomForestClassifier()\n",
    "param_dist = {\n",
    "    'n_estimators': [10, 50, 100],\n",
    "    'min_samples_leaf': [1, 2, 5]\n",
    "}\n",
    "grid = GridSearchCV(model, param_dist, cv=5)\n",
    "grid.fit(xtrain, ytrain)\n",
    "grid.best_score_, grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross-validation score for the tuned hyperparameters is very good.\n",
    "But the test set should give us the proper generalization score.\n",
    "Since this is a multilabel classification we can look at a classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "yfit = grid.best_estimator_.predict(xtest)\n",
    "print(classification_report(ytest, yfit, target_names=iris.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately this is a tiny dataset,\n",
    "therefore the support of the classes is very small.\n",
    "Yet, we can see what we expected: *setosa* is perfectly separated,\n",
    "and moreover, we have reasonable F1 score for the other classes.\n",
    "Note: the F1 score for *versicolor* and *virginica* will depend on the random\n",
    "split into the training and test set.\n",
    "\n",
    "Since this is a tiny dataset,\n",
    "let's throw a confusion matrix over all samples.\n",
    "Just to see if it matches our visual evaluation of the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "yfit_train = grid.best_estimator_.predict(xtrain)\n",
    "m = confusion_matrix(np.hstack([ytrain, ytest]), np.hstack([yfit_train, yfit]))\n",
    "fig = plt.figure(figsize=(5, 5))\n",
    "ax = sns.heatmap(m.T, square=True, annot=True, fmt='d', cmap='ocean_r',\n",
    "                 xticklabels=iris.target_names, yticklabels=iris.target_names)\n",
    "ax.set(xlabel='true label', ylabel='predicted label');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that's a pretty amazing result for a classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [sklearn - Importance of Feature Scaling][1]\n",
    "\n",
    "[1]: http://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
